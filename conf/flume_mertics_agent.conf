#===============================================
# Naming the components on the current agent
#===============================================
flume_metrics_agent.sources = http_metrics_src
flume_metrics_agent.channels = fc_metrics_ch_compressed
flume_metrics_agent.sinks = hdfs_metrics_sink_compressed

#============================================
# Describing/Configuring the HTTP source
#=============================================
flume_metrics_agent.sources.http_metrics_src.type = http
flume_metrics_agent.sources.http_metrics_src.port = <port number>
flume_metrics_agent.sources.http_metrics_src.bind = <ip address or domain name>
flume_metrics_agent.sources.http_metrics_src.handler = io.muhammadyaseen.github.flumeplugins.eventhandler.MetricsEventHandler
flume_metrics_agent.sources.http_metrics_src.channels = fc_metrics_ch_compressed


#=========================================================================
# Describing/Configuring the COMPRESSED sink
#=========================================================================
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.type = hdfs
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.hdfs.path = hdfs://your_hadoop_master:9000/path/to/metrics_folder/year=%Y/month=%m/day=%d
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.hdfs.filePrefix = metrics
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.hdfs.fileSuffix = .avro
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.hdfs.rollInterval = 0
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.hdfs.rollCount = 0
# file size to trigger roll (in bytes) 128 MB = 128*1048576 = 134217728
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.hdfs.rollSize = 804653184
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.hdfs.fileType = DataStream
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.hdfs.minBlockReplicas = 2
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.hdfs.batchSize = 3000
# 2 hrs
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.hdfs.idleTimeout = 7200
# Connect COMPRESSED channel to COMPRESSED sink
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.channel = fc_metrics_ch_compressed


#===========================================================================
# Configure AVRO serializer
#===========================================================================
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.serializer = io.muhammadyaseen.github.flumeplugins.eventserializer.MetricsEventAvroSerializer$Builder
flume_metrics_agent.sinks.hdfs_metrics_sink_compressed.serializer.compressionCodec = snappy


#===================================================================
# For COMPRESSED file  channel
#====================================================================
flume_metrics_agent.channels.fc_metrics_ch_compressed.type = file
# channel capacity:  30 million events ~ 2 days of metrics data
flume_metrics_agent.channels.fc_metrics_ch_compressed.capacity = 3000000
flume_metrics_agent.channels.fc_metrics_ch_compressed.transactionCapacity = 5000
flume_metrics_agent.channels.fc_metrics_ch_compressed.useDualCheckpoints = true
flume_metrics_agent.channels.fc_metrics_ch_compressed.checkpointDir = /home/hduser/flume_tmp/flume_metrics_agent/fc_metrics_ch_compressed/checkpoint_dir/
flume_metrics_agent.channels.fc_metrics_ch_compressed.backupCheckpointDir = /home/hduser/flume_tmp/flume_metrics_agent/fc_metrics_ch_compressed/bckup_checkpoint_dir/
flume_metrics_agent.channels.fc_metrics_ch_compressed.dataDirs = /home/hduser/flume_tmp/flume_metrics_agent/fc_metrics_ch_compressed/data_dir/
# max file size for file channel ~200mb
flume_metrics_agent.channels.fc_metrics_ch_compressed.maxFileSize = 209715200
# 100 seconds
flume_metrics_agent.channels.fc_metrics_ch_compressed.checkpointInterval = 100000